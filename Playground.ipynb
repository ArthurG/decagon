{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing\n",
    "\n",
    "from polypharmacy.utility import *\n",
    "\n",
    "# Train on CPU (hide GPU) due to memory constraints\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "# Train on GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "###########################################################\n",
    "#\n",
    "# Functions\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    edge_ind = 0\n",
    "    for u, v in edges_pos[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 1, 'Problem 1'\n",
    "\n",
    "        actual.append(edge_ind)\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    predicted = list(zip(*sorted(predicted, reverse=True, key=itemgetter(0))))[1]\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    apk_sc = rank_metrics.apk(actual, predicted, k=50)\n",
    "\n",
    "    return roc_sc, aupr_sc, apk_sc\n",
    "\n",
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: data/bio-decagon-ppi.csv\n",
      "Edges: 715612\n",
      "Nodes: 19081\n",
      "Reading: data/bio-decagon-targets.csv\n",
      "Reading: data/bio-decagon-combo.csv\n",
      "Drug combinations: 63473 Side effects: 1317\n",
      "Drug-drug interactions: 4649441\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#\n",
    "# Load and preprocess data \n",
    "#\n",
    "###########################################################\n",
    "\n",
    "####\n",
    "# Attempt to load in datasets and uses them to train the model\n",
    "# \n",
    "# All preprocessed datasets used in the drug combination study are at: http://snap.stanford.edu/decagon:\n",
    "# (1) Download datasets from http://snap.stanford.edu/decagon to your local machine.\n",
    "# (2) Replace dummy toy datasets used here with the actual datasets you just downloaded.\n",
    "# (3) Train & test the model.\n",
    "####\n",
    "\n",
    "val_test_size = 0.10\n",
    "\n",
    "\n",
    "gene_net, node2idx = load_ppi_v2(\"data/bio-decagon-ppi.csv\") # protein protein interactions\n",
    "stitch2proteins = load_targets(\"data/bio-decagon-targets.csv\") #drug protein interations\n",
    "combo2stitch, combo2se, se2name = load_combo_se('data/bio-decagon-combo.csv') #Drug drug interactions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with drug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running this, common_se holds a list of the side effects we're interested in predicting\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_se_counter(se_map):\n",
    "    side_effects = []\n",
    "    for drug in se_map:\n",
    "        side_effects += list(set(se_map[drug]))\n",
    "    return Counter(side_effects)\n",
    "\n",
    "combo_counter = get_se_counter(combo2se)\n",
    "\n",
    "common_se = []\n",
    "for se, count in combo_counter.most_common(964):\n",
    "    common_se += [se]\n",
    "common_se = set(common_se)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of side effects 964\n"
     ]
    }
   ],
   "source": [
    "# After running this cell, give each drug an unique integer ID. This will make it easier later to fill in the appropriate matricies\n",
    "# This mapping is stored in drug2idx\n",
    "\n",
    "# Each side effect is also given an unique integer ID. \n",
    "# This mapping is stored in se2idx\n",
    "\n",
    "# Proteins do not need to be given IDs, since the loader automatically generates such a unique id. \n",
    "\n",
    "drug2idx = {}\n",
    "idx = 0\n",
    "for combo, se_set in combo2se.items():     \n",
    "    if len(combo2se[combo].intersection(common_se)) == 0:\n",
    "        continue\n",
    "    drug_0 = combo.split(\"_\")[0]\n",
    "    drug_1 = combo.split(\"_\")[1]\n",
    "    if drug_0 not in drug2idx:\n",
    "        drug2idx[drug_0] = idx\n",
    "        idx+=1\n",
    "    if drug_1 not in drug2idx:\n",
    "        drug2idx[drug_1] = idx\n",
    "        idx+=1\n",
    "n_drugs = len(drug2idx)\n",
    "\n",
    "#count up all the unique side effects, give them a unique id\n",
    "idx = 0\n",
    "se2idx = {}\n",
    "for _, se_set in combo2se.items(): \n",
    "    for se in se_set:\n",
    "        if se not in se2idx and se in common_se:\n",
    "            se2idx[se] = idx\n",
    "            idx+=1\n",
    "        \n",
    "print(\"Number of side effects\", idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of drug-drug interactions 4576785\n"
     ]
    }
   ],
   "source": [
    "# Drug - drug interaction matrix\n",
    "# drug_drug_adj_list n matrixs. If drug_drug_adj_list[i][j][k] == 1, \n",
    "# then drug j interacts with drug k to cause side effect i\n",
    "\n",
    "drug_drug_adj_list = [np.zeros((n_drugs, n_drugs)) for _ in se2idx]\n",
    "\n",
    "count= 0\n",
    "for drug_drug, se_set in combo2se.items():\n",
    "    drug0 = drug_drug.split(\"_\")[0]\n",
    "    drug1 = drug_drug.split(\"_\")[1]\n",
    "    for se in se_set:\n",
    "        if drug0 in drug2idx and  drug1 in drug2idx and se in se2idx:\n",
    "            se_index = se2idx[se]\n",
    "            drug0_index = drug2idx[drug0]\n",
    "            drug1_index = drug2idx[drug1]\n",
    "            drug_drug_adj_list[se_index][drug0_index][drug1_index] = 1.        \n",
    "            drug_drug_adj_list[se_index][drug1_index][drug0_index] = 1.\n",
    "            count+=1\n",
    "        \n",
    "drug_drug_adj_list = [ sp.csr_matrix(item) for item in drug_drug_adj_list]\n",
    "drug_degrees_list = [np.array(drug_adj.sum(axis=0)).squeeze() for drug_adj in drug_drug_adj_list]\n",
    "        \n",
    "print(\"Number of drug-drug interactions\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with genes (aka proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proteins 19081\n"
     ]
    }
   ],
   "source": [
    "# The loader protein loader was modified very slightly to ensure this works. See polypharmacy.utility.load_ppi_v2\n",
    "\n",
    "gene_adj = nx.adjacency_matrix(gene_net)\n",
    "gene_degrees = np.array(gene_adj.sum(axis=0)).squeeze()\n",
    "n_genes = gene_adj.shape[0]\n",
    "print(\"Number of proteins\", n_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with drug - protein interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find 94 out of 18596 proteins (0.00505485050548505)\n",
      "Number of protein-drug edges 18596\n"
     ]
    }
   ],
   "source": [
    "# If gene_drug_matrix[i][j] == 1, then there is some interaction with protein i and drug j. \n",
    "\n",
    "missing = 0 \n",
    "present = 0\n",
    "gene_drug_matrix =  np.zeros((n_genes, n_drugs))\n",
    "for (drug_id, protein_set) in stitch2proteins.items():\n",
    "    drug_idx = drug2idx[drug_id]\n",
    "    for item in protein_set:\n",
    "        if item not in node2idx:\n",
    "            missing+=1\n",
    "        else:\n",
    "            protein_idx = node2idx[item]\n",
    "            gene_drug_matrix[protein_idx][drug_idx] = 1\n",
    "            present+=1\n",
    "print(\"Unable to find {} out of {} proteins ({})\".format(missing, present, missing/present))\n",
    "print(\"Number of protein-drug edges\", present)\n",
    "\n",
    "gene_drug_adj = sp.csr_matrix(gene_drug_matrix)\n",
    "drug_gene_adj = gene_drug_adj.transpose(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19081, 645)\n"
     ]
    }
   ],
   "source": [
    "print(gene_drug_adj.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code is directly copied from main.py. \n",
    "Minor changes may have been made since Jupyter doesn't work too well with flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge types: 1932\n"
     ]
    }
   ],
   "source": [
    "# data representation\n",
    "adj_mats_orig = {\n",
    "    (0, 0): [gene_adj, gene_adj.transpose(copy=True)],\n",
    "    (0, 1): [gene_drug_adj],\n",
    "    (1, 0): [drug_gene_adj],\n",
    "    (1, 1): drug_drug_adj_list + [x.transpose(copy=True) for x in drug_drug_adj_list]\n",
    "}\n",
    "degrees = {\n",
    "    0: [gene_degrees, gene_degrees],\n",
    "    1: drug_degrees_list + drug_degrees_list\n",
    "}\n",
    "\n",
    "# featureless (genes)\n",
    "gene_feat = sp.identity(n_genes)\n",
    "gene_nonzero_feat, gene_num_feat = gene_feat.shape\n",
    "gene_feat = preprocessing.sparse_to_tuple(gene_feat.tocoo())\n",
    "\n",
    "# features (drugs)\n",
    "drug_feat = sp.identity(n_drugs)\n",
    "drug_nonzero_feat, drug_num_feat = drug_feat.shape\n",
    "drug_feat = preprocessing.sparse_to_tuple(drug_feat.tocoo())\n",
    "\n",
    "# data representation\n",
    "num_feat = {\n",
    "    0: gene_num_feat,\n",
    "    1: drug_num_feat,\n",
    "}\n",
    "nonzero_feat = {\n",
    "    0: gene_nonzero_feat,\n",
    "    1: drug_nonzero_feat,\n",
    "}\n",
    "feat = {\n",
    "    0: gene_feat,\n",
    "    1: drug_feat,\n",
    "}\n",
    "\n",
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}\n",
    "edge_type2decoder = {\n",
    "    (0, 0): 'bilinear',\n",
    "    (0, 1): 'bilinear',\n",
    "    (1, 0): 'bilinear',\n",
    "    (1, 1): 'dedicom',\n",
    "}\n",
    "\n",
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}\n",
    "num_edge_types = sum(edge_types.values())\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#\n",
    "# Settings and placeholders\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 50, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 512, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')\n",
    "# Important -- Do not evaluate/print validation performance every iteration as it can take\n",
    "# substantial amount of time\n",
    "PRINT_PROGRESS_EVERY = 150\n",
    "\n",
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create minibatch iterator\n",
      "Minibatch edge type: (0, 0, 0)\n",
      "Constructing test edges= 0000/143122\n",
      "Constructing test edges= 1000/143122\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-053e888716ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0medge_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mval_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_test_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;32m~/Programming/decagon/decagon/deep/minibatch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, adj_mats, feat, edge_types, batch_size, val_test_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Minibatch edge type:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"(%d, %d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_test_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train edges=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%04d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_edges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/decagon/decagon/deep/minibatch.py\u001b[0m in \u001b[0;36mmask_test_edges\u001b[0;34m(self, edge_type, type_idx)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0midx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_mats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0midx_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_mats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ismember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest_edges_false\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/decagon/decagon/deep/minibatch.py\u001b[0m in \u001b[0;36m_ismember\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mrows_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#\n",
    "# Create minibatch iterator, model and optimizer\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "print(\"Create minibatch iterator\")\n",
    "minibatch = EdgeMinibatchIterator(\n",
    "    adj_mats=adj_mats_orig,\n",
    "    feat=feat,\n",
    "    edge_types=edge_types,\n",
    "    batch_size=512,\n",
    "    val_test_size=val_test_size\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "fileObject = open(\"minibatch.pickle\",'rb')  \n",
    "minibatch = pickle.dump(minibatch, fileObject)  \n",
    "fileObject.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decagon.deep.model import DecagonModel\n",
    "\n",
    "\n",
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=512,\n",
    "        margin=0.1\n",
    "    )\n",
    "\n",
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########################################################\n",
    "#\n",
    "# Train model\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "print(\"Train model\")\n",
    "for epoch in range(50):\n",
    "\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    while not minibatch.end():\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=0.1,\n",
    "            placeholders=placeholders)\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        train_cost = outs[1]\n",
    "        batch_edge_type = outs[2]\n",
    "\n",
    "        if itr % PRINT_PROGRESS_EVERY == 0:\n",
    "            val_auc, val_auprc, val_apk = get_accuracy_scores(\n",
    "                minibatch.val_edges, minibatch.val_edges_false,\n",
    "                minibatch.idx2edge_type[minibatch.current_edge_type_idx])\n",
    "\n",
    "            print(\"Epoch:\", \"%04d\" % (epoch + 1), \"Iter:\", \"%04d\" % (itr + 1), \"Edge:\", \"%04d\" % batch_edge_type,\n",
    "                  \"train_loss=\", \"{:.5f}\".format(train_cost),\n",
    "                  \"val_roc=\", \"{:.5f}\".format(val_auc), \"val_auprc=\", \"{:.5f}\".format(val_auprc),\n",
    "                  \"val_apk=\", \"{:.5f}\".format(val_apk), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "        itr += 1\n",
    "\n",
    "print(\"Optimization finished!\")\n",
    "\n",
    "for et in range(num_edge_types):\n",
    "    roc_score, auprc_score, apk_score = get_accuracy_scores(\n",
    "        minibatch.test_edges, minibatch.test_edges_false, minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type=\", \"[%02d, %02d, %02d]\" % minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(roc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(auprc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AP@k score\", \"{:.5f}\".format(apk_score))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
